{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "In this notebook, we will try to get a general overview of CNNs and what can be done with them.\n",
    "We will use the MNIST dataset.\n",
    "At the end of the notebook as an extra side, you can also try to implement something similar by loading the CIFAR-10 dataset.\n",
    "\n",
    "Please note that this notebook is not an advanced implementation of CNNs. It is just for you to learn ho to implement from scratch a simple CNN, without using any pre-trained network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Dataset\n",
    "\n",
    "The MNIST dataset is a large database of handwritten digits. It contains 60,000 training images and 10,000 testing images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import the packages that you may need.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import cifar10, mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Reshape\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import to_categorical\n",
    "#from seansUtils.research import StatsCallback, ModelSummary\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams['figure.figsize'] = (15, 8)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Load the MNIST dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Perform some data pre-processing on both input and labels. Hint: reshape the input with dimension (28,28,1)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1).astype('float32')\n",
    "train_images /= 255\n",
    "test_images /= 255\n",
    "train_labels = to_categorical(train_labels, 10)\n",
    "test_labels = to_categorical(test_labels, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Print the shape of the data and some sample to visualize them.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- THE DATA ---\n",
      "train_images shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "(60000, 28, 28, 1)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Print the Data\n",
    "print('--- THE DATA ---')\n",
    "print('train_images shape:', train_images.shape)\n",
    "print(train_images.shape[0], 'train samples')\n",
    "print(test_images.shape[0], 'test samples')\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla CNN\n",
    "\n",
    "This is the most basic CNN: you will have to build a convolutional neural network that is composed by 2 Convolutional layers and 2 Fully Connected layers. Use proper activation functions.\n",
    "\n",
    "- Convolutional layer: 32 filters, 3x3;\n",
    "- ReLU activation function;\n",
    "- Convolutional layer: 32 filters, 3x3;\n",
    "- ReLU activation function;\n",
    "- Flatten;\n",
    "- Fully Connected layer of size 128;\n",
    "- ReLU activation function;\n",
    "- Fully Connected layer of size 10;\n",
    "- Softmax activation function;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Set the number of batches and epochs. Without GPU please keep number of epochs under 10.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "batch_size = 64\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Build the Vanilla CNN model. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zennaro\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(28, 28, 1...)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\Zennaro\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "model_vanilla = Sequential()\n",
    "\n",
    "# 1st Conv Layer\n",
    "model_vanilla.add(Convolution2D(32, 3, 3, input_shape=(28, 28, 1)))\n",
    "model_vanilla.add(Activation('relu'))\n",
    "\n",
    "# 2nd Conv Layer\n",
    "model_vanilla.add(Convolution2D(32, 3, 3))\n",
    "model_vanilla.add(Activation('relu'))\n",
    "\n",
    "# Fully Connected Layer\n",
    "model_vanilla.add(Flatten())\n",
    "model_vanilla.add(Dense(128))\n",
    "model_vanilla.add(Activation('relu'))\n",
    "\n",
    "# Prediction output Layer\n",
    "model_vanilla.add(Dense(10))\n",
    "model_vanilla.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Get a summary of the model. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               2359424   \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 2,370,282\n",
      "Trainable params: 2,370,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_vanilla.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Configure the model with an optimizer and a loss. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vanilla.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Train the model. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zennaro\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 270s 5ms/step - loss: 0.1267 - acc: 0.9620\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 238s 4ms/step - loss: 0.0381 - acc: 0.9880\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 250s 4ms/step - loss: 0.0218 - acc: 0.9930\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 248s 4ms/step - loss: 0.0147 - acc: 0.9954\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0116 - acc: 0.9963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bdce4f3b38>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_vanilla.fit(train_images, train_labels, batch_size=batch_size, nb_epoch=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN with Max Pooling and Dropout\n",
    "\n",
    "Let's implement the same CNN as above but plus Max Pooling and Dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build the new network with max pooling and dropout. You should think a little bit where Max Pooling and Dropout should be inserted. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zennaro\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(28, 28, 1...)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\Zennaro\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "model_vanilla_pooling = Sequential()\n",
    "\n",
    "# 1st Convolutional Layer\n",
    "model_vanilla_pooling.add(Convolution2D(32, 3, 3, input_shape=(28, 28, 1)))\n",
    "model_vanilla_pooling.add(Activation('relu'))\n",
    "\n",
    "# 2nd Convolutional Layer\n",
    "model_vanilla_pooling.add(Convolution2D(32, 3, 3))\n",
    "model_vanilla_pooling.add(Activation('relu'))\n",
    "\n",
    "# Max Pooling\n",
    "model_vanilla_pooling.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "# Dropout\n",
    "model_vanilla_pooling.add(Dropout(0.25))\n",
    "\n",
    "# Fully Connected Layer\n",
    "model_vanilla_pooling.add(Flatten())\n",
    "model_vanilla_pooling.add(Dense(128))\n",
    "model_vanilla_pooling.add(Activation('relu'))\n",
    "    \n",
    "# More Dropout\n",
    "model_vanilla_pooling.add(Dropout(0.5))\n",
    "\n",
    "# Fully Connected Layer for Prediction\n",
    "model_vanilla_pooling.add(Dense(10))\n",
    "model_vanilla_pooling.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Get a summary of the model. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 600,810\n",
      "Trainable params: 600,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_vanilla_pooling.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Configure the network. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vanilla_pooling.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Train the network. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zennaro\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 243s 4ms/step - loss: 0.2282 - acc: 0.9313\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 203s 3ms/step - loss: 0.0911 - acc: 0.9732\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 214s 4ms/step - loss: 0.0688 - acc: 0.9791\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 218s 4ms/step - loss: 0.0581 - acc: 0.9827\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 222s 4ms/step - loss: 0.0500 - acc: 0.9843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bdcf928f28>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_vanilla_pooling.fit(train_images, train_labels, batch_size=batch_size, nb_epoch=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Evaluate the model on the test data. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 12s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model_vanilla_pooling.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Print the test accuracy. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9902\n"
     ]
    }
   ],
   "source": [
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra: More complex CNN with CIFAR-10\n",
    "\n",
    "As an extra part, you can also load the CIFAR-10 dataset, perform a similar data pre-processing as the MNIST dataset and implement a proper CNN. In this case, the dataset consists of 60,000 32x32 color images in 10 classes, with 6,000 images per class. Therefore you will need a network that is a little bit deeper, with 4 convolution layer. \n",
    "\n",
    "This part is not guided as the previous one, it's up to you to start from scratch and try out the implementation. However the procduere is pretty similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
